{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtupqrgSlvkG",
        "outputId": "869a7a3c-3f76-436d-bbb3-62d605609227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers rank-bm25 nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH9MnY6Pojdf",
        "outputId": "592d09b4-e517-420b-c2e8-c6453bbe1e67"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate rank-bm25 tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyKdUJYBonT2",
        "outputId": "c86dae4d-b49e-4a4a-c7bf-2ca2dce36b49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRO0i8J3lzDu",
        "outputId": "702e4a4d-6b9b-48db-ed46-0367efd29415"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "from rank_bm25 import BM25Okapi\n",
        "import re\n",
        "import evaluate\n",
        "from tqdm import tqdm\n",
        "\n",
        "def simple_tokenize(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "print(\"Loading SQuAD dataset...\")\n",
        "squad_dataset = load_dataset(\"squad\", split=\"validation[:100]\")\n",
        "\n",
        "contexts = list(set(example[\"context\"] for example in squad_dataset))\n",
        "tokenized_contexts = [simple_tokenize(doc) for doc in contexts]\n",
        "bm25 = BM25Okapi(tokenized_contexts)\n",
        "\n",
        "print(\"Loading QA model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "def answer_user_question(user_question, top_k=3, min_score=0.4):\n",
        "    tokenized_question = simple_tokenize(user_question)\n",
        "    scores = bm25.get_scores(tokenized_question)\n",
        "\n",
        "    best_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
        "    top_contexts = [contexts[i] for i in best_indices]\n",
        "\n",
        "    best_answer = {\"score\": 0, \"answer\": \"No answer found\", \"context\": \"\"}\n",
        "\n",
        "    for ctx in top_contexts:\n",
        "        try:\n",
        "            result = qa_pipeline({\n",
        "                \"question\": user_question,\n",
        "                \"context\": ctx\n",
        "            })\n",
        "            if result[\"score\"] > best_answer[\"score\"]:\n",
        "                best_answer = {\n",
        "                    \"score\": result[\"score\"],\n",
        "                    \"answer\": result[\"answer\"],\n",
        "                    \"context\": ctx\n",
        "                }\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if best_answer[\"score\"] < min_score:\n",
        "        return {\n",
        "            \"score\": best_answer[\"score\"],\n",
        "            \"answer\": \"Sorry, I couldn't find a reliable answer in the current dataset.\",\n",
        "            \"context\": \"\"\n",
        "        }\n",
        "\n",
        "    return best_answer\n",
        "\n",
        "def evaluate_model():\n",
        "    print(\"Running Evaluation on SQuAD subset...\")\n",
        "    squad_metric = evaluate.load(\"squad\")\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for example in tqdm(squad_dataset):\n",
        "        question = example[\"question\"]\n",
        "\n",
        "        tokenized_question = simple_tokenize(question)\n",
        "        scores = bm25.get_scores(tokenized_question)\n",
        "        best_idx = scores.argmax()\n",
        "        context = contexts[best_idx]\n",
        "\n",
        "        try:\n",
        "            result = qa_pipeline({\n",
        "                \"question\": question,\n",
        "                \"context\": context\n",
        "            })\n",
        "            predicted_answer = result[\"answer\"]\n",
        "        except:\n",
        "            predicted_answer = \"\"\n",
        "\n",
        "        predictions.append({\"prediction_text\": predicted_answer, \"id\": example[\"id\"]})\n",
        "        references.append({\"answers\": example[\"answers\"], \"id\": example[\"id\"]})\n",
        "\n",
        "    metrics = squad_metric.compute(predictions=predictions, references=references)\n",
        "    print(f\"\\nEvaluation Results on SQuAD (100 samples):\")\n",
        "    print(f\"Exact Match: {metrics['exact_match']:.2f}\")\n",
        "    print(f\"F1 Score:    {metrics['f1']:.2f}\")\n",
        "\n",
        "def main():\n",
        "    print(\"\\nRunning Built-in Questions...\\n\")\n",
        "\n",
        "    sample_questions = [\n",
        "        \"Who was the first president of the United States?\",\n",
        "        \"What is the capital of France?\",\n",
        "        \"How many planets are in the solar system?\",\n",
        "        \"Who discovered penicillin?\",\n",
        "        \"What is the boiling point of water?\"\n",
        "    ]\n",
        "\n",
        "    for question in sample_questions:\n",
        "        print(f\"Question: {question}\")\n",
        "        answer = answer_user_question(question)\n",
        "        print(f\"Answer: {answer['answer']}\")\n",
        "        print(f\"From Context: {answer['context'][:200]}...\")\n",
        "        print(f\"Confidence Score: {answer['score']:.4f}\\n\")\n",
        "\n",
        "    print(\"Evaluating model on SQuAD subset...\\n\")\n",
        "    evaluate_model()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP06TL0imTRF",
        "outputId": "b7c1a6c1-930f-4f5b-9a7a-a361c5e0ff23"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SQuAD dataset...\n",
            "Loading QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Built-in Questions...\n",
            "\n",
            "Question: Who was the first president of the United States?\n",
            "Answer: Cam Newton\n",
            "From Context: The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship ...\n",
            "Confidence Score: 0.9284\n",
            "\n",
            "Question: What is the capital of France?\n",
            "Answer: Sorry, I couldn't find a reliable answer in the current dataset.\n",
            "From Context: ...\n",
            "Confidence Score: 0.2526\n",
            "\n",
            "Question: How many planets are in the solar system?\n",
            "Answer: Sorry, I couldn't find a reliable answer in the current dataset.\n",
            "From Context: ...\n",
            "Confidence Score: 0.1590\n",
            "\n",
            "Question: Who discovered penicillin?\n",
            "Answer: Sorry, I couldn't find a reliable answer in the current dataset.\n",
            "From Context: ...\n",
            "Confidence Score: 0.3835\n",
            "\n",
            "Question: What is the boiling point of water?\n",
            "Answer: Sorry, I couldn't find a reliable answer in the current dataset.\n",
            "From Context: ...\n",
            "Confidence Score: 0.1434\n",
            "\n",
            "Evaluating model on SQuAD subset...\n",
            "\n",
            "Running Evaluation on SQuAD subset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:28<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results on SQuAD (100 samples):\n",
            "Exact Match: 54.00\n",
            "F1 Score:    56.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKRNEsDurwkW",
        "outputId": "1e82613a-14e9-495a-b0e5-3e5d78e6655e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=784868f9d001cee7bb9e33672e5cb6437756304b49b695dead4295116a332d34\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "from transformers import pipeline\n",
        "import re\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "\n",
        "# Set Wikipedia language\n",
        "wikipedia.set_lang(\"en\")\n",
        "\n",
        "# Load QA model\n",
        "print(\"Loading QA model...\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "def get_wikipedia_summary(query, sentences=5):\n",
        "    try:\n",
        "        search_results = wikipedia.search(query)\n",
        "        if not search_results:\n",
        "            return None\n",
        "        page = wikipedia.page(search_results[0])\n",
        "        content = page.content\n",
        "        return clean_text(\" \".join(content.split('.')[:sentences]) + '.')\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def answer_question(question, context, min_confidence=0.4):\n",
        "    try:\n",
        "        result = qa_pipeline({\n",
        "            \"question\": question,\n",
        "            \"context\": context\n",
        "        })\n",
        "        if result[\"score\"] < min_confidence:\n",
        "            result[\"answer\"] = \"Could not find a confident answer.\"\n",
        "        return {\n",
        "            \"answer\": result[\"answer\"],\n",
        "            \"context\": context[:300] + \"...\",\n",
        "            \"score\": result[\"score\"]\n",
        "        }\n",
        "    except Exception:\n",
        "        return {\n",
        "            \"answer\": \"Error during QA processing.\",\n",
        "            \"context\": \"\",\n",
        "            \"score\": 0\n",
        "        }\n",
        "\n",
        "# Custom metrics\n",
        "def normalize_answer(s):\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, ground_truth):\n",
        "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def compute_f1(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = set(prediction_tokens) & set(ground_truth_tokens)\n",
        "    if len(prediction_tokens) == 0 or len(ground_truth_tokens) == 0:\n",
        "        return int(len(prediction_tokens) == len(ground_truth_tokens))\n",
        "    if len(common) == 0:\n",
        "        return 0\n",
        "    precision = len(common) / len(prediction_tokens)\n",
        "    recall = len(common) / len(ground_truth_tokens)\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "def evaluate_on_squad(n=100):\n",
        "    print(\"Running Evaluation on SQuAD subset...\")\n",
        "    dataset = load_dataset(\"squad\", split=f\"validation[:{n}]\")\n",
        "    exact_match_score = 0\n",
        "    f1_score = 0\n",
        "\n",
        "    for sample in tqdm(dataset):\n",
        "        question = sample[\"question\"]\n",
        "        context = sample[\"context\"]\n",
        "        true_answers = sample[\"answers\"][\"text\"]\n",
        "        true_answer = true_answers[0] if true_answers else \"\"\n",
        "\n",
        "        result = answer_question(question, context)\n",
        "        predicted = result[\"answer\"]\n",
        "\n",
        "        exact_match_score += compute_exact_match(predicted, true_answer)\n",
        "        f1_score += compute_f1(predicted, true_answer)\n",
        "\n",
        "    exact_match_avg = exact_match_score / len(dataset) * 100\n",
        "    f1_avg = f1_score / len(dataset) * 100\n",
        "\n",
        "    print(f\"\\nEvaluation Results on SQuAD ({n} samples):\")\n",
        "    print(f\"Exact Match: {exact_match_avg:.2f}\")\n",
        "    print(f\"F1 Score:    {f1_avg:.2f}\")\n",
        "\n",
        "def main():\n",
        "    print(\"\\nWikipedia QA System (DistilBERT)\\n\")\n",
        "\n",
        "    built_in_questions = [\n",
        "        \"Who discovered gravity?\",\n",
        "        \"What is the theory of relativity?\",\n",
        "        \"Who painted the Mona Lisa?\",\n",
        "        \"What is quantum physics?\",\n",
        "        \"What causes climate change?\"\n",
        "    ]\n",
        "\n",
        "    for question in built_in_questions:\n",
        "        print(f\"Question: {question}\")\n",
        "        context = get_wikipedia_summary(question)\n",
        "        if context:\n",
        "            result = answer_question(question, context)\n",
        "            print(f\"Answer: {result['answer']}\")\n",
        "            print(f\"From Context: {result['context']}\")\n",
        "            print(f\"Confidence Score: {result['score']:.4f}\\n\")\n",
        "        else:\n",
        "            print(\"Answer: No relevant Wikipedia content found.\\n\")\n",
        "\n",
        "    # Automatically run evaluation on SQuAD\n",
        "    evaluate_on_squad(100)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z43Y6aXyr2My",
        "outputId": "50dd4977-045b-4ae7-b1e3-c80083de0b5b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wikipedia QA System (DistilBERT)\n",
            "\n",
            "Question: Who discovered gravity?\n",
            "Answer: No relevant Wikipedia content found.\n",
            "\n",
            "Question: What is the theory of relativity?\n",
            "Answer: Could not find a confident answer.\n",
            "From Context: In physics, the special theory of relativity, or special relativity for short, is a scientific theory of the relationship between space and time In Albert Einstein's 1905 paper, \"On the Electrodynamics of Moving Bodies\", the theory is presented as being based on just two postulates: The laws of phys...\n",
            "Confidence Score: 0.2698\n",
            "\n",
            "Question: Who painted the Mona Lisa?\n",
            "Answer: Leonardo da Vinci\n",
            "From Context: The Isleworth Mona Lisa is an early 16th-century oil on canvas painting depicting the same subject as Leonardo da Vinci's Mona Lisa, though with the subject (Lisa del Giocondo) depicted as being a younger age The painting is thought to have been brought from Italy to England in the 1780s, and came i...\n",
            "Confidence Score: 0.9488\n",
            "\n",
            "Question: What is quantum physics?\n",
            "Answer: Could not find a confident answer.\n",
            "From Context: Quantum mechanics is the fundamental physical theory that describes the behavior of matter and of light; its unusual characteristics typically occur at and below the scale of atoms : 1 1 It is the foundation of all quantum physics, which includes quantum chemistry, quantum field theory, quantum tech...\n",
            "Confidence Score: 0.0549\n",
            "\n",
            "Question: What causes climate change?\n",
            "Answer: Could not find a confident answer.\n",
            "From Context: The scientific community has been investigating the causes of climate change for decades After thousands of studies, the scientific consensus is that it is \"unequivocal that human influence has warmed the atmosphere, ocean and land since pre-industrial times \": 3 This consensus is supported by aroun...\n",
            "Confidence Score: 0.0451\n",
            "\n",
            "Running Evaluation on SQuAD subset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:28<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results on SQuAD (100 samples):\n",
            "Exact Match: 68.00\n",
            "F1 Score:    73.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n",
        "import re\n",
        "import string\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Set Wikipedia language\n",
        "wikipedia.set_lang(\"en\")\n",
        "\n",
        "# Load better QA model\n",
        "print(\"Loading enhanced QA model...\")\n",
        "model_name = \"deepset/roberta-base-squad2\"  # Better model trained on SQuAD v2\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Create pipeline with specific parameters\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    handle_impossible_answer=True\n",
        ")\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans excessive whitespaces in text.\"\"\"\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def get_wikipedia_content(query, max_length=2000):\n",
        "    \"\"\"Search and fetch Wikipedia content for a query.\"\"\"\n",
        "    try:\n",
        "        search_results = wikipedia.search(query)\n",
        "        if not search_results:\n",
        "            return None\n",
        "\n",
        "        # Try the first result\n",
        "        try:\n",
        "            page = wikipedia.page(search_results[0], auto_suggest=False)\n",
        "        except wikipedia.DisambiguationError as e:\n",
        "            # If disambiguation page, take the first option\n",
        "            if e.options:\n",
        "                page = wikipedia.page(e.options[0], auto_suggest=False)\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        # Get content\n",
        "        content = page.content\n",
        "\n",
        "        # Ensure we don't exceed the context window\n",
        "        if len(content) > max_length:\n",
        "            content = content[:max_length]\n",
        "\n",
        "        return clean_text(content)\n",
        "    except Exception as e:\n",
        "        print(f\"Wikipedia error: {e}\")\n",
        "        return None\n",
        "\n",
        "def answer_question(question, context, min_confidence=0.4):\n",
        "    \"\"\"Answer a question given the context using the QA model with improved handling.\"\"\"\n",
        "    try:\n",
        "        # Handle empty context\n",
        "        if not context:\n",
        "            return {\n",
        "                \"answer\": \"No relevant context found to answer the question.\",\n",
        "                \"context\": \"\",\n",
        "                \"score\": 0\n",
        "            }\n",
        "\n",
        "        # Handle context length - ensure it's not too long\n",
        "        if len(context) > 4000:\n",
        "            context = context[:4000]\n",
        "\n",
        "        # Get answer\n",
        "        result = qa_pipeline({\n",
        "            \"question\": question,\n",
        "            \"context\": context\n",
        "        })\n",
        "\n",
        "        # Improved confidence handling\n",
        "        if result[\"score\"] < min_confidence:\n",
        "            if \"I don't know\" in result[\"answer\"] or len(result[\"answer\"]) < 2:\n",
        "                result[\"answer\"] = \"Could not find a confident answer in the provided context.\"\n",
        "\n",
        "        return {\n",
        "            \"answer\": result[\"answer\"],\n",
        "            \"context\": context[:300] + \"...\" if len(context) > 300 else context,\n",
        "            \"score\": result[\"score\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"QA error: {e}\")\n",
        "        return {\n",
        "            \"answer\": \"Error during QA processing.\",\n",
        "            \"context\": \"\",\n",
        "            \"score\": 0\n",
        "        }\n",
        "\n",
        "# Custom evaluation functions\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, ground_truth):\n",
        "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def compute_f1(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "\n",
        "    # Calculate precision, recall, and F1\n",
        "    common = set(prediction_tokens) & set(ground_truth_tokens)\n",
        "\n",
        "    if len(prediction_tokens) == 0 or len(ground_truth_tokens) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if both are no-answer, 0 otherwise\n",
        "        return int(len(prediction_tokens) == len(ground_truth_tokens))\n",
        "\n",
        "    if len(common) == 0:\n",
        "        return 0\n",
        "\n",
        "    precision = len(common) / len(prediction_tokens)\n",
        "    recall = len(common) / len(ground_truth_tokens)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def evaluate_on_squad(n=100):\n",
        "    \"\"\"Evaluate the QA model on a subset of the SQuAD validation set.\"\"\"\n",
        "    print(f\"\\nRunning Evaluation on SQuAD ({n} samples)...\")\n",
        "    dataset = load_dataset(\"squad\", split=f\"validation[:{n}]\")\n",
        "\n",
        "    total_samples = len(dataset)\n",
        "    exact_match_score = 0\n",
        "    f1_score = 0\n",
        "\n",
        "    for sample in tqdm(dataset):\n",
        "        question = sample[\"question\"]\n",
        "        context = sample[\"context\"]\n",
        "        true_answers = sample[\"answers\"][\"text\"]\n",
        "        true_answer = true_answers[0] if true_answers else \"\"\n",
        "\n",
        "        result = answer_question(question, context)\n",
        "        predicted = result[\"answer\"]\n",
        "\n",
        "        # Calculate scores using our custom functions\n",
        "        exact_match_score += compute_exact_match(predicted, true_answer)\n",
        "        f1_score += compute_f1(predicted, true_answer)\n",
        "\n",
        "    # Compute average scores\n",
        "    exact_match_avg = exact_match_score / total_samples * 100\n",
        "    f1_avg = f1_score / total_samples * 100\n",
        "\n",
        "    print(f\"\\nEvaluation Results on SQuAD ({n} samples):\")\n",
        "    print(f\"Exact Match: {exact_match_avg:.2f}\")\n",
        "    print(f\"F1 Score:    {f1_avg:.2f}\")\n",
        "\n",
        "    return exact_match_avg, f1_avg\n",
        "\n",
        "# Built-in test questions across different domains - reduced to 4\n",
        "test_questions = [\n",
        "    \"Who invented the World Wide Web?\",\n",
        "    \"What is the theory of relativity?\",\n",
        "    \"Who was the first president of the United States?\",\n",
        "    \"What is artificial intelligence?\"\n",
        "]\n",
        "\n",
        "def run_built_in_questions():\n",
        "    \"\"\"Run tests on built-in questions and display results.\"\"\"\n",
        "    questions_to_run = test_questions\n",
        "\n",
        "    print(f\"\\nRunning {len(questions_to_run)} built-in questions...\\n\")\n",
        "\n",
        "    results = []\n",
        "    for i, question in enumerate(questions_to_run):\n",
        "        print(f\"Question {i+1}: {question}\")\n",
        "\n",
        "        # Get context from Wikipedia\n",
        "        context = get_wikipedia_content(question)\n",
        "\n",
        "        # Get answer\n",
        "        start_time = time.time()\n",
        "        result = answer_question(question, context)\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        # Display results\n",
        "        print(f\"Answer: {result['answer']}\")\n",
        "        print(f\"Confidence: {result['score']:.4f}\")\n",
        "        print(f\"Response time: {elapsed_time:.2f} seconds\")\n",
        "        print(f\"Context snippet: {result['context'][:150]}...\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # Save results\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"answer\": result['answer'],\n",
        "            \"confidence\": result['score'],\n",
        "            \"response_time\": elapsed_time\n",
        "        })\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_confidence = sum(r['confidence'] for r in results) / len(results)\n",
        "    avg_response_time = sum(r['response_time'] for r in results) / len(results)\n",
        "\n",
        "    print(\"\\nSummary:\")\n",
        "    print(f\"Average confidence: {avg_confidence:.4f}\")\n",
        "    print(f\"Average response time: {avg_response_time:.2f} seconds\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the automatic QA system.\"\"\"\n",
        "    print(\"\\nAutomated Wikipedia QA System\")\n",
        "    print(\"============================\")\n",
        "\n",
        "    # Run SQuAD evaluation\n",
        "    print(\"\\nPart 1: SQuAD Evaluation\")\n",
        "    squad_em, squad_f1 = evaluate_on_squad(100)\n",
        "\n",
        "    # Run built-in questions\n",
        "    print(\"\\nPart 2: Built-in Questions Test\")\n",
        "    question_results = run_built_in_questions()\n",
        "\n",
        "    # Display final summary\n",
        "    print(\"\\nFinal Summary\")\n",
        "    print(\"=============\")\n",
        "    print(f\"SQuAD Evaluation Results:\")\n",
        "    print(f\"- Exact Match: {squad_em:.2f}\")\n",
        "    print(f\"- F1 Score: {squad_f1:.2f}\")\n",
        "    print(f\"Built-in Questions Results:\")\n",
        "    print(f\"- Questions tested: {len(question_results)}\")\n",
        "    print(f\"- Average confidence: {sum(r['confidence'] for r in question_results) / len(question_results):.4f}\")\n",
        "    print(f\"- Average response time: {sum(r['response_time'] for r in question_results) / len(question_results):.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPJgUitX1JUB",
        "outputId": "8634f878-9063-4d82-8b70-cf8793e14e08"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading enhanced QA model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Automated Wikipedia QA System\n",
            "============================\n",
            "\n",
            "Part 1: SQuAD Evaluation\n",
            "\n",
            "Running Evaluation on SQuAD (100 samples)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:00<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Results on SQuAD (100 samples):\n",
            "Exact Match: 81.00\n",
            "F1 Score:    84.24\n",
            "\n",
            "Part 2: Built-in Questions Test\n",
            "\n",
            "Running 4 built-in questions...\n",
            "\n",
            "Question 1: Who invented the World Wide Web?\n",
            "Answer: Tim Berners-Lee\n",
            "Confidence: 0.9274\n",
            "Response time: 2.46 seconds\n",
            "Context snippet: The World Wide Web (\"WWW\", \"W3\" or simply \"the Web\") is a global information medium that users can access via computers connected to the Internet. The...\n",
            "--------------------------------------------------------------------------------\n",
            "Question 2: What is the theory of relativity?\n",
            "Answer: special relativity and general relativity\n",
            "Confidence: 0.1439\n",
            "Response time: 2.26 seconds\n",
            "Context snippet: The theory of relativity usually encompasses two interrelated physics theories by Albert Einstein: special relativity and general relativity, proposed...\n",
            "--------------------------------------------------------------------------------\n",
            "Question 3: Who was the first president of the United States?\n",
            "Answer: George Washington\n",
            "Confidence: 0.9617\n",
            "Response time: 2.40 seconds\n",
            "Context snippet: The president of the United States is the head of state and head of government of the United States, indirectly elected to a four-year term via the El...\n",
            "--------------------------------------------------------------------------------\n",
            "Question 4: What is artificial intelligence?\n",
            "Answer: an academic discipline\n",
            "Confidence: 0.4372\n",
            "Response time: 3.02 seconds\n",
            "Context snippet: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Summary:\n",
            "Average confidence: 0.6175\n",
            "Average response time: 2.53 seconds\n",
            "\n",
            "Final Summary\n",
            "=============\n",
            "SQuAD Evaluation Results:\n",
            "- Exact Match: 81.00\n",
            "- F1 Score: 84.24\n",
            "Built-in Questions Results:\n",
            "- Questions tested: 4\n",
            "- Average confidence: 0.6175\n",
            "- Average response time: 2.53 seconds\n"
          ]
        }
      ]
    }
  ]
}